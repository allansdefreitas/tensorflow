{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-3-public/blob/main/Course%201%20-%20Custom%20Models%2C%20Layers%20and%20Loss%20Functions/Week%204%20-%20Models/C1_W4_Lab_2_resnet-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing ResNet\n",
    "\n",
    "In this lab, you will continue exploring Model subclassing by building a more complex architecture. \n",
    "\n",
    "[Residual Networks](https://arxiv.org/abs/1512.03385) make use of skip connections to make deep models easier to train. \n",
    "- There are branches as well as many repeating blocks of layers in this type of network. \n",
    "- You can define a model class to help organize this more complex code, and to make it easier to re-use your code when building the model.\n",
    "- As before, you will inherit from the [Model class](https://keras.io/api/models/model/) so that you can make use of the other built-in methods that Keras provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmI9MQA6Z72_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Model subclasses\n",
    "\n",
    "As shown in the lectures, you will first implement the Identity Block which contains the skip connections (i.e. the `add()` operation below. This will also inherit the Model class and implement the `__init__()` and `call()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FIkYUttchv5"
   },
   "outputs": [],
   "source": [
    "class IdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(IdentityBlock, self).__init__(name='')\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "        self.add = tf.keras.layers.Add()\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = self.add([x, input_tensor])\n",
    "        x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, you can build the rest of the ResNet model. \n",
    "- You will call your `IdentityBlock` class two times below and that takes care of inserting those blocks of layers into this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnMkmeecxw28"
   },
   "outputs": [],
   "source": [
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.act = tf.keras.layers.Activation('relu')\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D((3, 3))\n",
    "\n",
    "        # Use the Identity blocks that you just defined\n",
    "        self.id1a = IdentityBlock(64, 3)\n",
    "        self.id1b = IdentityBlock(64, 3)\n",
    "\n",
    "        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # insert the identity blocks in the middle of the network\n",
    "        x = self.id1a(x)\n",
    "        x = self.id1b(x)\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "As mentioned before, inheriting the Model class allows you to make use of the other APIs that Keras provides, such as:\n",
    "- training\n",
    "- serialization\n",
    "- evaluation\n",
    "\n",
    "You can instantiate a Resnet object and train it as usual like below:\n",
    "\n",
    "**Note**: If you have issues with training in the Coursera lab environment, you can also run this in Colab using the \"open in colab\" badge link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dMHKPz_dIc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset mnist (11.06 MiB) to ./data\\mnist\\1.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AC:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\urllib3\\connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\urllib3\\connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\urllib3\\connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\urllib3\\connectionpool.py:1052: InsecureRequestWarning: Unverified HTTPS request is being made to host 'storage.googleapis.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/9 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.19 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/2 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.02 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:06,  1.37 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:05,  1.37 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  2.02 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.19 url/s]\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  4.16 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.49 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  4.16 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.49 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  4.16 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  2.02 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  3.49 url/s]\n",
      "Dl Size...:  40%|████      | 4/10 [00:00<00:01,  5.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  2.02 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  40%|████      | 4/10 [00:01<00:01,  5.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  50%|█████     | 5/10 [00:01<00:00,  5.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  2.94 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]\n",
      "Dl Size...:  60%|██████    | 6/10 [00:01<00:00,  6.90 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  70%|███████   | 7/10 [00:01<00:00,  6.90 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  2.94 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]\n",
      "Dl Size...:  80%|████████  | 8/10 [00:01<00:00,  8.21 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  90%|█████████ | 9/10 [00:01<00:00,  8.21 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 3/3 [00:01<00:00,  2.94 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.49 url/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  9.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.40 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  9.11 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.40 url/s]4 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  9.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.94 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.40 url/s]2 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  9.11 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:01<00:00,  2.07 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:01<00:00,  5.16 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:01<00:00,  2.06 url/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffling...:   0%|          | 0/10 [00:00<?, ? shard/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\allan.freitas\\Anaconda3\\envs\\allan-cv\\lib\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Writing...:  97%|█████████▋| 5791/6000 [00:00<00:00, 57650.28 examples/s]\u001b[A\n",
      "Shuffling...:  10%|█         | 1/10 [00:00<00:01,  8.27 shard/s]         \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  20%|██        | 2/10 [00:00<00:00,  8.36 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  30%|███       | 3/10 [00:00<00:00,  8.56 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  40%|████      | 4/10 [00:00<00:00,  8.62 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  50%|█████     | 5/10 [00:00<00:00,  8.68 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  60%|██████    | 6/10 [00:00<00:00,  8.69 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  70%|███████   | 7/10 [00:00<00:00,  8.62 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:  80%|████████  | 8/10 [00:00<00:00,  8.95 shard/s]\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Writing...: 100%|█████████▉| 5988/6000 [00:00<00:00, 59768.34 examples/s]\u001b[A\n",
      "Shuffling...:  90%|█████████ | 9/10 [00:01<00:00,  8.60 shard/s]         \u001b[A\n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling...:   0%|          | 0/1 [00:00<?, ? shard/s]          \n",
      "Reading...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                            \u001b[A\n",
      "Writing...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Writing...:  66%|██████▋   | 6629/10000 [00:00<00:00, 66276.32 examples/s]\u001b[A\n",
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mnist downloaded and prepared to ./data\\mnist\\1.0.0. Subsequent calls will reuse this data.\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.1309 - accuracy: 0.9651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a960e9a08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utility function to normalize the images and return (image, label) pairs.\n",
    "def preprocess(features):\n",
    "    return tf.cast(features['image'], tf.float32) / 255., features['label']\n",
    "\n",
    "# create a ResNet instance with 10 output units for MNIST\n",
    "resnet = ResNet(10)\n",
    "resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# load and preprocess the dataset\n",
    "dataset = tfds.load('mnist', split=tfds.Split.TRAIN, data_dir='./data')\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# train the model.\n",
    "resnet.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ResNetExample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
